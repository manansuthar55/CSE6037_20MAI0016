{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# VIT-Vellore, SCOPE\n## CSE6037 - Deep Learning and its Applications\n### SUTHAR MANAN BHARATKUMAR 20MAI0016\n### Assessment 5\n***GitHub Link:*** https://github.com/manansuthar55/CSE6037_20MAI0016/tree/main/Assessment_5\n#### Problem 1: Vanilla RNN.","metadata":{}},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.metrics import accuracy_score\nfrom keras.datasets import reuters\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.utils import to_categorical\nfrom keras.models import Sequential\nfrom keras.layers import Dense, SimpleRNN, Activation\nfrom keras import optimizers\nfrom keras.wrappers.scikit_learn import KerasClassifier\n\nnum_words = 30000\nmaxlen = 50\ntest_split = 0.3\n\n(X_train, y_train), (X_test, y_test) = reuters.load_data(num_words = num_words, maxlen = maxlen, test_split = test_split)\nX_train = pad_sequences(X_train, padding = 'post')\nX_test = pad_sequences(X_test, padding = 'post')\nX_train = np.array(X_train).reshape((X_train.shape[0], X_train.shape[1], 1))\nX_test = np.array(X_test).reshape((X_test.shape[0], X_test.shape[1], 1))\ny_data = np.concatenate((y_train, y_test))\ny_data = to_categorical(y_data)\ny_train = y_data[:1395]\ny_test = y_data[1395:]\n\ndef vanilla_rnn():\n    model = Sequential()\n    model.add(SimpleRNN(50, input_shape = (49,1), return_sequences = False))\n    model.add(Dense(46))\n    model.add(Activation('softmax'))\n    adam = optimizers.Adam(lr = 0.001)\n    model.compile(loss = 'categorical_crossentropy', optimizer = adam, metrics = ['accuracy'])\n    return model\n\nmodel = KerasClassifier(build_fn = vanilla_rnn, epochs = 200, batch_size = 50, verbose = 1)\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_test)\ny_test_ = np.argmax(y_test, axis = 1)\nprint(accuracy_score(y_pred, y_test_))","metadata":{"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters.npz\n2113536/2110848 [==============================] - 0s 0us/step\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/datasets/reuters.py:148: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/datasets/reuters.py:149: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/200\n28/28 [==============================] - 1s 10ms/step - loss: 3.2570 - accuracy: 0.2723\nEpoch 2/200\n28/28 [==============================] - 0s 10ms/step - loss: 1.3573 - accuracy: 0.7074\nEpoch 3/200\n28/28 [==============================] - 0s 10ms/step - loss: 1.2419 - accuracy: 0.6976\nEpoch 4/200\n28/28 [==============================] - 0s 10ms/step - loss: 1.1771 - accuracy: 0.7066\nEpoch 5/200\n28/28 [==============================] - 0s 10ms/step - loss: 1.2220 - accuracy: 0.6985\nEpoch 6/200\n28/28 [==============================] - 0s 10ms/step - loss: 1.1966 - accuracy: 0.7055\nEpoch 7/200\n28/28 [==============================] - 0s 10ms/step - loss: 1.2120 - accuracy: 0.6933\nEpoch 8/200\n28/28 [==============================] - 0s 10ms/step - loss: 1.0856 - accuracy: 0.7275\nEpoch 9/200\n28/28 [==============================] - 0s 10ms/step - loss: 1.1530 - accuracy: 0.7091\nEpoch 10/200\n28/28 [==============================] - 0s 10ms/step - loss: 1.2208 - accuracy: 0.6951\nEpoch 11/200\n28/28 [==============================] - 0s 10ms/step - loss: 1.1334 - accuracy: 0.7158\nEpoch 12/200\n28/28 [==============================] - 0s 10ms/step - loss: 1.1213 - accuracy: 0.7314\nEpoch 13/200\n28/28 [==============================] - 0s 10ms/step - loss: 1.1725 - accuracy: 0.7084\nEpoch 14/200\n28/28 [==============================] - 0s 10ms/step - loss: 1.1624 - accuracy: 0.7100\nEpoch 15/200\n28/28 [==============================] - 0s 10ms/step - loss: 1.1513 - accuracy: 0.7130\nEpoch 16/200\n28/28 [==============================] - 0s 10ms/step - loss: 1.1596 - accuracy: 0.7156\nEpoch 17/200\n28/28 [==============================] - 0s 10ms/step - loss: 1.1194 - accuracy: 0.7258\nEpoch 18/200\n28/28 [==============================] - 0s 10ms/step - loss: 1.1024 - accuracy: 0.7188\nEpoch 19/200\n28/28 [==============================] - 0s 10ms/step - loss: 1.1304 - accuracy: 0.7113\nEpoch 20/200\n28/28 [==============================] - 0s 10ms/step - loss: 1.1263 - accuracy: 0.7160\nEpoch 21/200\n28/28 [==============================] - 0s 10ms/step - loss: 1.1488 - accuracy: 0.7044\nEpoch 22/200\n28/28 [==============================] - 0s 10ms/step - loss: 1.1778 - accuracy: 0.6987\nEpoch 23/200\n28/28 [==============================] - 0s 10ms/step - loss: 1.0729 - accuracy: 0.7311\nEpoch 24/200\n28/28 [==============================] - 0s 11ms/step - loss: 1.1301 - accuracy: 0.7089\nEpoch 25/200\n28/28 [==============================] - 0s 11ms/step - loss: 1.2205 - accuracy: 0.6943\nEpoch 26/200\n28/28 [==============================] - 0s 10ms/step - loss: 1.1437 - accuracy: 0.7191\nEpoch 27/200\n28/28 [==============================] - 0s 10ms/step - loss: 1.1685 - accuracy: 0.6985\nEpoch 28/200\n28/28 [==============================] - 0s 10ms/step - loss: 1.1402 - accuracy: 0.6987\nEpoch 29/200\n28/28 [==============================] - 0s 10ms/step - loss: 1.1781 - accuracy: 0.6923\nEpoch 30/200\n28/28 [==============================] - 0s 10ms/step - loss: 1.1194 - accuracy: 0.7129\nEpoch 31/200\n28/28 [==============================] - 0s 10ms/step - loss: 1.0868 - accuracy: 0.7217\nEpoch 32/200\n28/28 [==============================] - 0s 10ms/step - loss: 1.1153 - accuracy: 0.7016\nEpoch 33/200\n28/28 [==============================] - 0s 10ms/step - loss: 1.0571 - accuracy: 0.7189\nEpoch 34/200\n28/28 [==============================] - 0s 10ms/step - loss: 1.1026 - accuracy: 0.7137\nEpoch 35/200\n28/28 [==============================] - 0s 10ms/step - loss: 1.0466 - accuracy: 0.7282\nEpoch 36/200\n28/28 [==============================] - 0s 10ms/step - loss: 0.9737 - accuracy: 0.7482\nEpoch 37/200\n28/28 [==============================] - 0s 10ms/step - loss: 1.0428 - accuracy: 0.7168\nEpoch 38/200\n28/28 [==============================] - 0s 10ms/step - loss: 1.0465 - accuracy: 0.7201\nEpoch 39/200\n28/28 [==============================] - 0s 10ms/step - loss: 1.0553 - accuracy: 0.7154\nEpoch 40/200\n28/28 [==============================] - 0s 10ms/step - loss: 1.1192 - accuracy: 0.7027\nEpoch 41/200\n28/28 [==============================] - 0s 10ms/step - loss: 1.2325 - accuracy: 0.6942\nEpoch 42/200\n28/28 [==============================] - 0s 10ms/step - loss: 1.1276 - accuracy: 0.7106\nEpoch 43/200\n28/28 [==============================] - 0s 10ms/step - loss: 1.1103 - accuracy: 0.7161\nEpoch 44/200\n28/28 [==============================] - 0s 10ms/step - loss: 1.0825 - accuracy: 0.7107\nEpoch 45/200\n28/28 [==============================] - 0s 10ms/step - loss: 1.1140 - accuracy: 0.7135\nEpoch 46/200\n28/28 [==============================] - 0s 10ms/step - loss: 1.0818 - accuracy: 0.7147\nEpoch 47/200\n28/28 [==============================] - 0s 10ms/step - loss: 1.0928 - accuracy: 0.7144\nEpoch 48/200\n28/28 [==============================] - 0s 10ms/step - loss: 1.0815 - accuracy: 0.7144\nEpoch 49/200\n28/28 [==============================] - 0s 10ms/step - loss: 1.0962 - accuracy: 0.6997\nEpoch 50/200\n28/28 [==============================] - 0s 10ms/step - loss: 1.0705 - accuracy: 0.7184\nEpoch 51/200\n28/28 [==============================] - 0s 10ms/step - loss: 1.1487 - accuracy: 0.6961\nEpoch 52/200\n28/28 [==============================] - 0s 10ms/step - loss: 1.1244 - accuracy: 0.7076\nEpoch 53/200\n28/28 [==============================] - 0s 10ms/step - loss: 1.0408 - accuracy: 0.7149\nEpoch 54/200\n28/28 [==============================] - 0s 10ms/step - loss: 1.1144 - accuracy: 0.6912\nEpoch 55/200\n28/28 [==============================] - 0s 10ms/step - loss: 1.1291 - accuracy: 0.6917\nEpoch 56/200\n28/28 [==============================] - 0s 10ms/step - loss: 1.0492 - accuracy: 0.7028\nEpoch 57/200\n28/28 [==============================] - 0s 10ms/step - loss: 0.9994 - accuracy: 0.7267\nEpoch 58/200\n28/28 [==============================] - 0s 10ms/step - loss: 1.0542 - accuracy: 0.7266\nEpoch 59/200\n28/28 [==============================] - 0s 10ms/step - loss: 1.0206 - accuracy: 0.7087\nEpoch 60/200\n28/28 [==============================] - 0s 10ms/step - loss: 1.0896 - accuracy: 0.7046\nEpoch 61/200\n28/28 [==============================] - 0s 10ms/step - loss: 1.0880 - accuracy: 0.7152\nEpoch 62/200\n28/28 [==============================] - 0s 10ms/step - loss: 1.0578 - accuracy: 0.7134\nEpoch 63/200\n28/28 [==============================] - 0s 10ms/step - loss: 1.0569 - accuracy: 0.7194\nEpoch 64/200\n28/28 [==============================] - 0s 11ms/step - loss: 1.0459 - accuracy: 0.7093\nEpoch 65/200\n28/28 [==============================] - 0s 10ms/step - loss: 1.1039 - accuracy: 0.7050\nEpoch 66/200\n28/28 [==============================] - 0s 10ms/step - loss: 1.0062 - accuracy: 0.7235\nEpoch 67/200\n28/28 [==============================] - 0s 10ms/step - loss: 1.0310 - accuracy: 0.7062\nEpoch 68/200\n28/28 [==============================] - 0s 10ms/step - loss: 1.0740 - accuracy: 0.7135\nEpoch 69/200\n28/28 [==============================] - 0s 10ms/step - loss: 1.1003 - accuracy: 0.7034\nEpoch 70/200\n28/28 [==============================] - 0s 10ms/step - loss: 1.0270 - accuracy: 0.7282\nEpoch 71/200\n28/28 [==============================] - 0s 9ms/step - loss: 1.0911 - accuracy: 0.7012\nEpoch 72/200\n28/28 [==============================] - 0s 10ms/step - loss: 1.0531 - accuracy: 0.7162\nEpoch 73/200\n28/28 [==============================] - 0s 10ms/step - loss: 1.0795 - accuracy: 0.7157\nEpoch 74/200\n28/28 [==============================] - 0s 9ms/step - loss: 1.0571 - accuracy: 0.7114\nEpoch 75/200\n28/28 [==============================] - 0s 10ms/step - loss: 1.0915 - accuracy: 0.6996\nEpoch 76/200\n28/28 [==============================] - 0s 10ms/step - loss: 1.0320 - accuracy: 0.7202\nEpoch 77/200\n28/28 [==============================] - 0s 10ms/step - loss: 1.0314 - accuracy: 0.7251\nEpoch 78/200\n28/28 [==============================] - 0s 10ms/step - loss: 1.0147 - accuracy: 0.7173\nEpoch 79/200\n28/28 [==============================] - 0s 10ms/step - loss: 1.0822 - accuracy: 0.7065\nEpoch 80/200\n28/28 [==============================] - 0s 10ms/step - loss: 0.9986 - accuracy: 0.7304\nEpoch 81/200\n28/28 [==============================] - 0s 10ms/step - loss: 1.0253 - accuracy: 0.7161\nEpoch 82/200\n28/28 [==============================] - 0s 10ms/step - loss: 1.0482 - accuracy: 0.7206\nEpoch 83/200\n28/28 [==============================] - 0s 10ms/step - loss: 1.0062 - accuracy: 0.7261\nEpoch 84/200\n28/28 [==============================] - 0s 12ms/step - loss: 1.0046 - accuracy: 0.7292\nEpoch 85/200\n28/28 [==============================] - 0s 12ms/step - loss: 1.0751 - accuracy: 0.7083\nEpoch 86/200\n28/28 [==============================] - 0s 11ms/step - loss: 1.0635 - accuracy: 0.6935\nEpoch 87/200\n28/28 [==============================] - 0s 11ms/step - loss: 1.0843 - accuracy: 0.7131\nEpoch 88/200\n28/28 [==============================] - 0s 10ms/step - loss: 1.0312 - accuracy: 0.7237\nEpoch 89/200\n28/28 [==============================] - 0s 10ms/step - loss: 0.9976 - accuracy: 0.7215\nEpoch 90/200\n28/28 [==============================] - 0s 10ms/step - loss: 1.0229 - accuracy: 0.7189\nEpoch 91/200\n28/28 [==============================] - 0s 10ms/step - loss: 1.0934 - accuracy: 0.6988\nEpoch 92/200\n28/28 [==============================] - 0s 10ms/step - loss: 1.0421 - accuracy: 0.7129\nEpoch 93/200\n28/28 [==============================] - 0s 10ms/step - loss: 1.0252 - accuracy: 0.7186\nEpoch 94/200\n28/28 [==============================] - 0s 10ms/step - loss: 0.9928 - accuracy: 0.7193\nEpoch 95/200\n28/28 [==============================] - 0s 10ms/step - loss: 0.9928 - accuracy: 0.7276\nEpoch 96/200\n28/28 [==============================] - 0s 10ms/step - loss: 1.0276 - accuracy: 0.7301\nEpoch 97/200\n28/28 [==============================] - 0s 10ms/step - loss: 1.0595 - accuracy: 0.7159\nEpoch 98/200\n28/28 [==============================] - 0s 10ms/step - loss: 1.0025 - accuracy: 0.7319\nEpoch 99/200\n28/28 [==============================] - 0s 10ms/step - loss: 1.0174 - accuracy: 0.7162\nEpoch 100/200\n28/28 [==============================] - 0s 10ms/step - loss: 1.0931 - accuracy: 0.7035\nEpoch 101/200\n28/28 [==============================] - 0s 10ms/step - loss: 0.9780 - accuracy: 0.7372\nEpoch 102/200\n28/28 [==============================] - 0s 10ms/step - loss: 1.0297 - accuracy: 0.7264\nEpoch 103/200\n28/28 [==============================] - 0s 11ms/step - loss: 1.0096 - accuracy: 0.7275\nEpoch 104/200\n28/28 [==============================] - 0s 10ms/step - loss: 1.0343 - accuracy: 0.7142\nEpoch 105/200\n28/28 [==============================] - 0s 10ms/step - loss: 1.0203 - accuracy: 0.7221\nEpoch 106/200\n28/28 [==============================] - 0s 10ms/step - loss: 1.0550 - accuracy: 0.7099\nEpoch 107/200\n28/28 [==============================] - 0s 10ms/step - loss: 1.0166 - accuracy: 0.7147\nEpoch 108/200\n28/28 [==============================] - 0s 10ms/step - loss: 1.0700 - accuracy: 0.7131\nEpoch 109/200\n28/28 [==============================] - 0s 9ms/step - loss: 0.9809 - accuracy: 0.7288\nEpoch 110/200\n28/28 [==============================] - 0s 10ms/step - loss: 0.9770 - accuracy: 0.7172\nEpoch 111/200\n28/28 [==============================] - 0s 10ms/step - loss: 0.9981 - accuracy: 0.7218\nEpoch 112/200\n28/28 [==============================] - 0s 10ms/step - loss: 1.0367 - accuracy: 0.7148\nEpoch 113/200\n28/28 [==============================] - 0s 10ms/step - loss: 1.0129 - accuracy: 0.7226\nEpoch 114/200\n28/28 [==============================] - 0s 10ms/step - loss: 1.0385 - accuracy: 0.7143\nEpoch 115/200\n28/28 [==============================] - 0s 10ms/step - loss: 1.1156 - accuracy: 0.6951\nEpoch 116/200\n28/28 [==============================] - 0s 10ms/step - loss: 1.0320 - accuracy: 0.7126\nEpoch 117/200\n28/28 [==============================] - 0s 10ms/step - loss: 1.0516 - accuracy: 0.7021\nEpoch 118/200\n28/28 [==============================] - 0s 10ms/step - loss: 1.0136 - accuracy: 0.7161\nEpoch 119/200\n28/28 [==============================] - 0s 10ms/step - loss: 0.9688 - accuracy: 0.7188\nEpoch 120/200\n28/28 [==============================] - 0s 10ms/step - loss: 1.0378 - accuracy: 0.7131\nEpoch 121/200\n28/28 [==============================] - 0s 9ms/step - loss: 1.0092 - accuracy: 0.7328\nEpoch 122/200\n28/28 [==============================] - 0s 10ms/step - loss: 0.9888 - accuracy: 0.7356\nEpoch 123/200\n28/28 [==============================] - 0s 10ms/step - loss: 0.9878 - accuracy: 0.7254\nEpoch 124/200\n28/28 [==============================] - 0s 10ms/step - loss: 0.9200 - accuracy: 0.7432\nEpoch 125/200\n28/28 [==============================] - 0s 10ms/step - loss: 1.0509 - accuracy: 0.7152\nEpoch 126/200\n28/28 [==============================] - 0s 10ms/step - loss: 1.0007 - accuracy: 0.7306\nEpoch 127/200\n28/28 [==============================] - 0s 10ms/step - loss: 1.0782 - accuracy: 0.6985\nEpoch 128/200\n28/28 [==============================] - 0s 10ms/step - loss: 0.9829 - accuracy: 0.7161\nEpoch 129/200\n28/28 [==============================] - 0s 10ms/step - loss: 1.0514 - accuracy: 0.7051\nEpoch 130/200\n28/28 [==============================] - 0s 10ms/step - loss: 1.0301 - accuracy: 0.7071\nEpoch 131/200\n28/28 [==============================] - 0s 10ms/step - loss: 1.0056 - accuracy: 0.7231\nEpoch 132/200\n28/28 [==============================] - 0s 10ms/step - loss: 1.0153 - accuracy: 0.7178\nEpoch 133/200\n28/28 [==============================] - 0s 10ms/step - loss: 0.9673 - accuracy: 0.7317\nEpoch 134/200\n28/28 [==============================] - 0s 10ms/step - loss: 0.9911 - accuracy: 0.7305\nEpoch 135/200\n28/28 [==============================] - 0s 10ms/step - loss: 1.0351 - accuracy: 0.6979\nEpoch 136/200\n28/28 [==============================] - 0s 10ms/step - loss: 0.9968 - accuracy: 0.7232\nEpoch 137/200\n28/28 [==============================] - 0s 10ms/step - loss: 0.9412 - accuracy: 0.7338\nEpoch 138/200\n28/28 [==============================] - 0s 10ms/step - loss: 0.9918 - accuracy: 0.7143\nEpoch 139/200\n28/28 [==============================] - 0s 10ms/step - loss: 0.9827 - accuracy: 0.7209\nEpoch 140/200\n28/28 [==============================] - 0s 10ms/step - loss: 0.9792 - accuracy: 0.7262\nEpoch 141/200\n28/28 [==============================] - 0s 10ms/step - loss: 1.0471 - accuracy: 0.6969\nEpoch 142/200\n28/28 [==============================] - 0s 11ms/step - loss: 0.9784 - accuracy: 0.7259\nEpoch 143/200\n28/28 [==============================] - 0s 10ms/step - loss: 0.9746 - accuracy: 0.7244\nEpoch 144/200\n28/28 [==============================] - 0s 10ms/step - loss: 1.0529 - accuracy: 0.7038\nEpoch 145/200\n28/28 [==============================] - 0s 10ms/step - loss: 1.0439 - accuracy: 0.6974\nEpoch 146/200\n28/28 [==============================] - 0s 10ms/step - loss: 0.9638 - accuracy: 0.7288\nEpoch 147/200\n28/28 [==============================] - 0s 10ms/step - loss: 0.9458 - accuracy: 0.7370\nEpoch 148/200\n28/28 [==============================] - 0s 10ms/step - loss: 0.9631 - accuracy: 0.7314\nEpoch 149/200\n28/28 [==============================] - 0s 10ms/step - loss: 0.9334 - accuracy: 0.7369\nEpoch 150/200\n28/28 [==============================] - 0s 9ms/step - loss: 0.8958 - accuracy: 0.7443\nEpoch 151/200\n28/28 [==============================] - 0s 10ms/step - loss: 0.9571 - accuracy: 0.7319\nEpoch 152/200\n28/28 [==============================] - 0s 10ms/step - loss: 0.9601 - accuracy: 0.7234\nEpoch 153/200\n28/28 [==============================] - 0s 10ms/step - loss: 0.9971 - accuracy: 0.7151\nEpoch 154/200\n28/28 [==============================] - 0s 10ms/step - loss: 0.9539 - accuracy: 0.7315\nEpoch 155/200\n28/28 [==============================] - 0s 10ms/step - loss: 0.9670 - accuracy: 0.7239\nEpoch 156/200\n28/28 [==============================] - 0s 10ms/step - loss: 0.9917 - accuracy: 0.7252\nEpoch 157/200\n28/28 [==============================] - 0s 10ms/step - loss: 1.1638 - accuracy: 0.6944\nEpoch 158/200\n28/28 [==============================] - 0s 10ms/step - loss: 0.9988 - accuracy: 0.7149\nEpoch 159/200\n28/28 [==============================] - 0s 10ms/step - loss: 0.9806 - accuracy: 0.7302\nEpoch 160/200\n28/28 [==============================] - 0s 10ms/step - loss: 1.0079 - accuracy: 0.7156\nEpoch 161/200\n28/28 [==============================] - 0s 10ms/step - loss: 1.0259 - accuracy: 0.7005\nEpoch 162/200\n28/28 [==============================] - 0s 10ms/step - loss: 0.9868 - accuracy: 0.7168\nEpoch 163/200\n28/28 [==============================] - 0s 10ms/step - loss: 0.9614 - accuracy: 0.7345\nEpoch 164/200\n28/28 [==============================] - 0s 9ms/step - loss: 0.9765 - accuracy: 0.7204\nEpoch 165/200\n28/28 [==============================] - 0s 10ms/step - loss: 0.9580 - accuracy: 0.7234\nEpoch 166/200\n28/28 [==============================] - 0s 10ms/step - loss: 0.9713 - accuracy: 0.7167\nEpoch 167/200\n28/28 [==============================] - 0s 10ms/step - loss: 1.0149 - accuracy: 0.7171\nEpoch 168/200\n28/28 [==============================] - 0s 10ms/step - loss: 1.0438 - accuracy: 0.7062\nEpoch 169/200\n28/28 [==============================] - 0s 10ms/step - loss: 0.9577 - accuracy: 0.7241\nEpoch 170/200\n28/28 [==============================] - 0s 9ms/step - loss: 1.0106 - accuracy: 0.7106\nEpoch 171/200\n28/28 [==============================] - 0s 10ms/step - loss: 0.9974 - accuracy: 0.7157\nEpoch 172/200\n28/28 [==============================] - 0s 10ms/step - loss: 0.9655 - accuracy: 0.7108\nEpoch 173/200\n28/28 [==============================] - 0s 10ms/step - loss: 0.9986 - accuracy: 0.7132\nEpoch 174/200\n28/28 [==============================] - 0s 10ms/step - loss: 0.9801 - accuracy: 0.7142\nEpoch 175/200\n28/28 [==============================] - 0s 10ms/step - loss: 0.9721 - accuracy: 0.7304\nEpoch 176/200\n28/28 [==============================] - 0s 10ms/step - loss: 0.8847 - accuracy: 0.7512\nEpoch 177/200\n28/28 [==============================] - 0s 10ms/step - loss: 0.9745 - accuracy: 0.7296\nEpoch 178/200\n28/28 [==============================] - 0s 10ms/step - loss: 1.0236 - accuracy: 0.6995\nEpoch 179/200\n28/28 [==============================] - 0s 10ms/step - loss: 0.9751 - accuracy: 0.7277\nEpoch 180/200\n28/28 [==============================] - 0s 10ms/step - loss: 1.0056 - accuracy: 0.7175\nEpoch 181/200\n28/28 [==============================] - 0s 10ms/step - loss: 0.9455 - accuracy: 0.7221\nEpoch 182/200\n28/28 [==============================] - 0s 12ms/step - loss: 0.8936 - accuracy: 0.7424\nEpoch 183/200\n28/28 [==============================] - 0s 10ms/step - loss: 0.9338 - accuracy: 0.7286\nEpoch 184/200\n28/28 [==============================] - 0s 10ms/step - loss: 1.0115 - accuracy: 0.7218\nEpoch 185/200\n28/28 [==============================] - 0s 10ms/step - loss: 0.9038 - accuracy: 0.7347\nEpoch 186/200\n28/28 [==============================] - 0s 10ms/step - loss: 0.9014 - accuracy: 0.7317\nEpoch 187/200\n28/28 [==============================] - 0s 10ms/step - loss: 1.0032 - accuracy: 0.7049\nEpoch 188/200\n28/28 [==============================] - 0s 10ms/step - loss: 0.9931 - accuracy: 0.7220\nEpoch 189/200\n28/28 [==============================] - 0s 10ms/step - loss: 0.9817 - accuracy: 0.7205\nEpoch 190/200\n28/28 [==============================] - 0s 10ms/step - loss: 0.9539 - accuracy: 0.7343\nEpoch 191/200\n28/28 [==============================] - 0s 10ms/step - loss: 0.9839 - accuracy: 0.7077\nEpoch 192/200\n28/28 [==============================] - 0s 10ms/step - loss: 0.9662 - accuracy: 0.7259\nEpoch 193/200\n28/28 [==============================] - 0s 10ms/step - loss: 1.0064 - accuracy: 0.7144\nEpoch 194/200\n28/28 [==============================] - 0s 10ms/step - loss: 0.9175 - accuracy: 0.7401\nEpoch 195/200\n28/28 [==============================] - 0s 10ms/step - loss: 0.9779 - accuracy: 0.7140\nEpoch 196/200\n28/28 [==============================] - 0s 10ms/step - loss: 0.9872 - accuracy: 0.7020\nEpoch 197/200\n28/28 [==============================] - 0s 10ms/step - loss: 0.9179 - accuracy: 0.7271\nEpoch 198/200\n28/28 [==============================] - 0s 10ms/step - loss: 0.8815 - accuracy: 0.7478\nEpoch 199/200\n28/28 [==============================] - 0s 9ms/step - loss: 0.9013 - accuracy: 0.7295\nEpoch 200/200\n28/28 [==============================] - 0s 10ms/step - loss: 0.9075 - accuracy: 0.7381\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n  warnings.warn('`model.predict_classes()` is deprecated and '\n","output_type":"stream"},{"name":"stdout","text":"12/12 [==============================] - 0s 5ms/step\n0.7495826377295493\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#### Problem 2: LSTM.","metadata":{}},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.metrics import accuracy_score\nfrom keras.datasets import reuters\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.utils import to_categorical\nfrom keras.models import Sequential\nfrom keras.layers import Dense, LSTM, Activation\nfrom keras import optimizers\nfrom keras.wrappers.scikit_learn import KerasClassifier\n\nnum_words = 30000\nmaxlen = 50\ntest_split = 0.3\n(X_train, y_train), (X_test, y_test) = reuters.load_data(num_words = num_words, maxlen = maxlen, test_split = test_split)\nX_train = pad_sequences(X_train, padding = 'post')\nX_test = pad_sequences(X_test, padding = 'post')\nX_train = np.array(X_train).reshape((X_train.shape[0], X_train.shape[1], 1))\nX_test = np.array(X_test).reshape((X_test.shape[0], X_test.shape[1], 1))\ny_data = np.concatenate((y_train, y_test))\ny_data = to_categorical(y_data)\ny_train = y_data[:1395]\ny_test = y_data[1395:]\n\ndef lstm():\n    model = Sequential()\n    model.add(LSTM(50, input_shape = (49,1), return_sequences = False))\n    model.add(Dense(46))\n    model.add(Activation('softmax'))\n    adam = optimizers.Adam(lr = 0.001)\n    model.compile(loss = 'categorical_crossentropy', optimizer = adam, metrics = ['accuracy'])\n    return model\n\nmodel = KerasClassifier(build_fn = lstm, epochs = 200, batch_size = 50, verbose = 1)\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_test)\ny_test_ = np.argmax(y_test, axis = 1)\nprint(accuracy_score(y_pred, y_test_))","metadata":{"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/datasets/reuters.py:148: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/datasets/reuters.py:149: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/200\n28/28 [==============================] - 2s 23ms/step - loss: 3.5812 - accuracy: 0.3967\nEpoch 2/200\n28/28 [==============================] - 1s 24ms/step - loss: 1.4365 - accuracy: 0.7232\nEpoch 3/200\n28/28 [==============================] - 1s 24ms/step - loss: 1.1865 - accuracy: 0.7246\nEpoch 4/200\n28/28 [==============================] - 1s 24ms/step - loss: 1.3119 - accuracy: 0.6912\nEpoch 5/200\n28/28 [==============================] - 1s 26ms/step - loss: 1.1047 - accuracy: 0.7252\nEpoch 6/200\n28/28 [==============================] - 1s 25ms/step - loss: 1.1215 - accuracy: 0.7231\nEpoch 7/200\n28/28 [==============================] - 1s 25ms/step - loss: 1.1157 - accuracy: 0.7169\nEpoch 8/200\n28/28 [==============================] - 1s 25ms/step - loss: 1.0667 - accuracy: 0.7259\nEpoch 9/200\n28/28 [==============================] - 1s 25ms/step - loss: 1.0607 - accuracy: 0.7197\nEpoch 10/200\n28/28 [==============================] - 1s 24ms/step - loss: 0.9781 - accuracy: 0.7337\nEpoch 11/200\n28/28 [==============================] - 1s 25ms/step - loss: 0.9754 - accuracy: 0.7372\nEpoch 12/200\n28/28 [==============================] - 1s 25ms/step - loss: 0.8783 - accuracy: 0.8070\nEpoch 13/200\n28/28 [==============================] - 1s 26ms/step - loss: 0.8732 - accuracy: 0.7920\nEpoch 14/200\n28/28 [==============================] - 1s 24ms/step - loss: 0.8906 - accuracy: 0.7897\nEpoch 15/200\n28/28 [==============================] - 1s 23ms/step - loss: 0.8607 - accuracy: 0.7950\nEpoch 16/200\n28/28 [==============================] - 1s 23ms/step - loss: 0.8627 - accuracy: 0.8083\nEpoch 17/200\n28/28 [==============================] - 1s 23ms/step - loss: 0.7985 - accuracy: 0.8192\nEpoch 18/200\n28/28 [==============================] - 1s 23ms/step - loss: 0.7906 - accuracy: 0.8124\nEpoch 19/200\n28/28 [==============================] - 1s 23ms/step - loss: 0.8163 - accuracy: 0.7958\nEpoch 20/200\n28/28 [==============================] - 1s 23ms/step - loss: 0.8227 - accuracy: 0.8094\nEpoch 21/200\n28/28 [==============================] - 1s 24ms/step - loss: 0.7227 - accuracy: 0.8372\nEpoch 22/200\n28/28 [==============================] - 1s 24ms/step - loss: 0.7608 - accuracy: 0.8182\nEpoch 23/200\n28/28 [==============================] - 1s 23ms/step - loss: 0.7613 - accuracy: 0.8220\nEpoch 24/200\n28/28 [==============================] - 1s 23ms/step - loss: 0.7303 - accuracy: 0.8246\nEpoch 25/200\n28/28 [==============================] - 1s 24ms/step - loss: 0.7652 - accuracy: 0.8242\nEpoch 26/200\n28/28 [==============================] - 1s 22ms/step - loss: 0.8589 - accuracy: 0.8031\nEpoch 27/200\n28/28 [==============================] - 1s 23ms/step - loss: 0.7205 - accuracy: 0.8268\nEpoch 28/200\n28/28 [==============================] - 1s 22ms/step - loss: 0.8501 - accuracy: 0.8069\nEpoch 29/200\n28/28 [==============================] - 1s 23ms/step - loss: 0.7671 - accuracy: 0.8253\nEpoch 30/200\n28/28 [==============================] - 1s 23ms/step - loss: 0.7197 - accuracy: 0.8259\nEpoch 31/200\n28/28 [==============================] - 1s 23ms/step - loss: 0.7172 - accuracy: 0.8327\nEpoch 32/200\n28/28 [==============================] - 1s 24ms/step - loss: 0.7401 - accuracy: 0.8293\nEpoch 33/200\n28/28 [==============================] - 1s 23ms/step - loss: 0.6767 - accuracy: 0.8328\nEpoch 34/200\n28/28 [==============================] - 1s 23ms/step - loss: 0.7129 - accuracy: 0.8291\nEpoch 35/200\n28/28 [==============================] - 1s 23ms/step - loss: 0.7206 - accuracy: 0.8390\nEpoch 36/200\n28/28 [==============================] - 1s 23ms/step - loss: 0.7288 - accuracy: 0.8266\nEpoch 37/200\n28/28 [==============================] - 1s 23ms/step - loss: 0.7293 - accuracy: 0.8195\nEpoch 38/200\n28/28 [==============================] - 1s 25ms/step - loss: 0.7101 - accuracy: 0.8251\nEpoch 39/200\n28/28 [==============================] - 1s 23ms/step - loss: 0.7443 - accuracy: 0.8240\nEpoch 40/200\n28/28 [==============================] - 1s 23ms/step - loss: 0.6852 - accuracy: 0.8338\nEpoch 41/200\n28/28 [==============================] - 1s 23ms/step - loss: 0.7407 - accuracy: 0.8215\nEpoch 42/200\n28/28 [==============================] - 1s 22ms/step - loss: 0.7030 - accuracy: 0.8246\nEpoch 43/200\n28/28 [==============================] - 1s 23ms/step - loss: 0.6946 - accuracy: 0.8298\nEpoch 44/200\n28/28 [==============================] - 1s 23ms/step - loss: 0.6245 - accuracy: 0.8524\nEpoch 45/200\n28/28 [==============================] - 1s 22ms/step - loss: 0.6892 - accuracy: 0.8304\nEpoch 46/200\n28/28 [==============================] - 1s 26ms/step - loss: 0.7872 - accuracy: 0.8119\nEpoch 47/200\n28/28 [==============================] - 1s 27ms/step - loss: 0.7470 - accuracy: 0.8204\nEpoch 48/200\n28/28 [==============================] - 1s 23ms/step - loss: 0.7011 - accuracy: 0.8276\nEpoch 49/200\n28/28 [==============================] - 1s 24ms/step - loss: 0.6743 - accuracy: 0.8404\nEpoch 50/200\n28/28 [==============================] - 1s 23ms/step - loss: 0.7173 - accuracy: 0.8219\nEpoch 51/200\n28/28 [==============================] - 1s 23ms/step - loss: 0.7496 - accuracy: 0.8181\nEpoch 52/200\n28/28 [==============================] - 1s 23ms/step - loss: 0.6771 - accuracy: 0.8315\nEpoch 53/200\n28/28 [==============================] - 1s 24ms/step - loss: 0.6672 - accuracy: 0.8416\nEpoch 54/200\n28/28 [==============================] - 1s 23ms/step - loss: 0.7011 - accuracy: 0.8286\nEpoch 55/200\n28/28 [==============================] - 1s 25ms/step - loss: 0.6374 - accuracy: 0.8439\nEpoch 56/200\n28/28 [==============================] - 1s 23ms/step - loss: 0.6783 - accuracy: 0.8330\nEpoch 57/200\n28/28 [==============================] - 1s 23ms/step - loss: 0.6600 - accuracy: 0.8362\nEpoch 58/200\n28/28 [==============================] - 1s 23ms/step - loss: 0.6818 - accuracy: 0.8407\nEpoch 59/200\n28/28 [==============================] - 1s 23ms/step - loss: 0.6840 - accuracy: 0.8388\nEpoch 60/200\n28/28 [==============================] - 1s 23ms/step - loss: 0.6599 - accuracy: 0.8425\nEpoch 61/200\n28/28 [==============================] - 1s 24ms/step - loss: 0.6636 - accuracy: 0.8333\nEpoch 62/200\n28/28 [==============================] - 1s 22ms/step - loss: 0.6572 - accuracy: 0.8422\nEpoch 63/200\n28/28 [==============================] - 1s 24ms/step - loss: 0.6516 - accuracy: 0.8506\nEpoch 64/200\n28/28 [==============================] - 1s 23ms/step - loss: 0.6406 - accuracy: 0.8459\nEpoch 65/200\n28/28 [==============================] - 1s 23ms/step - loss: 0.6582 - accuracy: 0.8401\nEpoch 66/200\n28/28 [==============================] - 1s 23ms/step - loss: 0.5887 - accuracy: 0.8544\nEpoch 67/200\n28/28 [==============================] - 1s 22ms/step - loss: 0.6197 - accuracy: 0.8509\nEpoch 68/200\n28/28 [==============================] - 1s 22ms/step - loss: 0.6376 - accuracy: 0.8493\nEpoch 69/200\n28/28 [==============================] - 1s 22ms/step - loss: 0.6717 - accuracy: 0.8299\nEpoch 70/200\n28/28 [==============================] - 1s 23ms/step - loss: 0.7025 - accuracy: 0.8278\nEpoch 71/200\n28/28 [==============================] - 1s 23ms/step - loss: 0.5910 - accuracy: 0.8578\nEpoch 72/200\n28/28 [==============================] - 1s 25ms/step - loss: 0.6108 - accuracy: 0.8462\nEpoch 73/200\n28/28 [==============================] - 1s 23ms/step - loss: 0.6616 - accuracy: 0.8415\nEpoch 74/200\n28/28 [==============================] - 1s 24ms/step - loss: 0.6774 - accuracy: 0.8284\nEpoch 75/200\n28/28 [==============================] - 1s 24ms/step - loss: 0.6095 - accuracy: 0.8548\nEpoch 76/200\n28/28 [==============================] - 1s 24ms/step - loss: 0.6605 - accuracy: 0.8416\nEpoch 77/200\n28/28 [==============================] - 1s 23ms/step - loss: 0.6038 - accuracy: 0.8492\nEpoch 78/200\n28/28 [==============================] - 1s 24ms/step - loss: 0.6516 - accuracy: 0.8366\nEpoch 79/200\n28/28 [==============================] - 1s 24ms/step - loss: 0.5617 - accuracy: 0.8563\nEpoch 80/200\n28/28 [==============================] - 1s 24ms/step - loss: 0.6268 - accuracy: 0.8483\nEpoch 81/200\n28/28 [==============================] - 1s 22ms/step - loss: 0.6424 - accuracy: 0.8323\nEpoch 82/200\n28/28 [==============================] - 1s 23ms/step - loss: 0.5646 - accuracy: 0.8567\nEpoch 83/200\n28/28 [==============================] - 1s 23ms/step - loss: 0.6319 - accuracy: 0.8407\nEpoch 84/200\n28/28 [==============================] - 1s 23ms/step - loss: 0.5727 - accuracy: 0.8536\nEpoch 85/200\n28/28 [==============================] - 1s 23ms/step - loss: 0.5876 - accuracy: 0.8500\nEpoch 86/200\n28/28 [==============================] - 1s 23ms/step - loss: 0.5608 - accuracy: 0.8600\nEpoch 87/200\n28/28 [==============================] - 1s 22ms/step - loss: 0.6202 - accuracy: 0.8345\nEpoch 88/200\n28/28 [==============================] - 1s 23ms/step - loss: 0.5810 - accuracy: 0.8532\nEpoch 89/200\n28/28 [==============================] - 1s 23ms/step - loss: 0.5527 - accuracy: 0.8589\nEpoch 90/200\n28/28 [==============================] - 1s 22ms/step - loss: 0.6202 - accuracy: 0.8303\nEpoch 91/200\n28/28 [==============================] - 1s 23ms/step - loss: 0.5413 - accuracy: 0.8571\nEpoch 92/200\n28/28 [==============================] - 1s 23ms/step - loss: 0.6060 - accuracy: 0.8442\nEpoch 93/200\n28/28 [==============================] - 1s 23ms/step - loss: 0.6150 - accuracy: 0.8364\nEpoch 94/200\n28/28 [==============================] - 1s 23ms/step - loss: 0.5959 - accuracy: 0.8413\nEpoch 95/200\n28/28 [==============================] - 1s 24ms/step - loss: 0.6832 - accuracy: 0.8237\nEpoch 96/200\n28/28 [==============================] - 1s 26ms/step - loss: 0.5607 - accuracy: 0.8522\nEpoch 97/200\n28/28 [==============================] - 1s 26ms/step - loss: 0.6410 - accuracy: 0.8336\nEpoch 98/200\n28/28 [==============================] - 1s 23ms/step - loss: 0.5626 - accuracy: 0.8562\nEpoch 99/200\n28/28 [==============================] - 1s 23ms/step - loss: 0.5880 - accuracy: 0.8492\nEpoch 100/200\n28/28 [==============================] - 1s 23ms/step - loss: 0.5449 - accuracy: 0.8534\nEpoch 101/200\n28/28 [==============================] - 1s 23ms/step - loss: 0.5397 - accuracy: 0.8536\nEpoch 102/200\n28/28 [==============================] - 1s 23ms/step - loss: 0.5703 - accuracy: 0.8564\nEpoch 103/200\n28/28 [==============================] - 1s 23ms/step - loss: 0.4803 - accuracy: 0.8679\nEpoch 104/200\n28/28 [==============================] - 1s 22ms/step - loss: 0.5373 - accuracy: 0.8587\nEpoch 105/200\n28/28 [==============================] - 1s 25ms/step - loss: 0.5525 - accuracy: 0.8589\nEpoch 106/200\n28/28 [==============================] - 1s 24ms/step - loss: 0.5530 - accuracy: 0.8550\nEpoch 107/200\n28/28 [==============================] - 1s 23ms/step - loss: 0.5752 - accuracy: 0.8391\nEpoch 108/200\n28/28 [==============================] - 1s 23ms/step - loss: 0.5245 - accuracy: 0.8591\nEpoch 109/200\n28/28 [==============================] - 1s 23ms/step - loss: 0.6286 - accuracy: 0.8301\nEpoch 110/200\n28/28 [==============================] - 1s 23ms/step - loss: 0.6042 - accuracy: 0.8348\nEpoch 111/200\n28/28 [==============================] - 1s 23ms/step - loss: 0.5784 - accuracy: 0.8455\nEpoch 112/200\n28/28 [==============================] - 1s 23ms/step - loss: 0.5706 - accuracy: 0.8485\nEpoch 113/200\n28/28 [==============================] - 1s 23ms/step - loss: 0.5931 - accuracy: 0.8388\nEpoch 114/200\n28/28 [==============================] - 1s 23ms/step - loss: 0.5165 - accuracy: 0.8648\nEpoch 115/200\n28/28 [==============================] - 1s 23ms/step - loss: 0.6047 - accuracy: 0.8376\nEpoch 116/200\n28/28 [==============================] - 1s 24ms/step - loss: 0.5611 - accuracy: 0.8441\nEpoch 117/200\n28/28 [==============================] - 1s 23ms/step - loss: 0.5399 - accuracy: 0.8544\nEpoch 118/200\n28/28 [==============================] - 1s 24ms/step - loss: 0.5264 - accuracy: 0.8619\nEpoch 119/200\n28/28 [==============================] - 1s 23ms/step - loss: 0.5162 - accuracy: 0.8633\nEpoch 120/200\n28/28 [==============================] - 1s 23ms/step - loss: 0.4966 - accuracy: 0.8707\nEpoch 121/200\n28/28 [==============================] - 1s 23ms/step - loss: 0.5331 - accuracy: 0.8538\nEpoch 122/200\n28/28 [==============================] - 1s 25ms/step - loss: 0.4990 - accuracy: 0.8588\nEpoch 123/200\n28/28 [==============================] - 1s 23ms/step - loss: 0.5435 - accuracy: 0.8571\nEpoch 124/200\n28/28 [==============================] - 1s 23ms/step - loss: 0.5356 - accuracy: 0.8525\nEpoch 125/200\n28/28 [==============================] - 1s 24ms/step - loss: 0.5223 - accuracy: 0.8570\nEpoch 126/200\n28/28 [==============================] - 1s 23ms/step - loss: 0.5192 - accuracy: 0.8546\nEpoch 127/200\n28/28 [==============================] - 1s 24ms/step - loss: 0.4832 - accuracy: 0.8594\nEpoch 128/200\n28/28 [==============================] - 1s 23ms/step - loss: 0.5022 - accuracy: 0.8658\nEpoch 129/200\n28/28 [==============================] - 1s 23ms/step - loss: 0.5516 - accuracy: 0.8483\nEpoch 130/200\n28/28 [==============================] - 1s 22ms/step - loss: 0.4809 - accuracy: 0.8682\nEpoch 131/200\n28/28 [==============================] - 1s 24ms/step - loss: 0.5023 - accuracy: 0.8618\nEpoch 132/200\n28/28 [==============================] - 1s 23ms/step - loss: 0.5550 - accuracy: 0.8469\nEpoch 133/200\n28/28 [==============================] - 1s 23ms/step - loss: 0.4979 - accuracy: 0.8594\nEpoch 134/200\n28/28 [==============================] - 1s 23ms/step - loss: 0.4920 - accuracy: 0.8583\nEpoch 135/200\n28/28 [==============================] - 1s 23ms/step - loss: 0.4548 - accuracy: 0.8765\nEpoch 136/200\n28/28 [==============================] - 1s 23ms/step - loss: 0.5459 - accuracy: 0.8470\nEpoch 137/200\n28/28 [==============================] - 1s 23ms/step - loss: 0.4394 - accuracy: 0.8697\nEpoch 138/200\n28/28 [==============================] - 1s 23ms/step - loss: 0.5046 - accuracy: 0.8640\nEpoch 139/200\n28/28 [==============================] - 1s 25ms/step - loss: 0.4638 - accuracy: 0.8798\nEpoch 140/200\n28/28 [==============================] - 1s 23ms/step - loss: 0.4887 - accuracy: 0.8652\nEpoch 141/200\n28/28 [==============================] - 1s 23ms/step - loss: 0.5335 - accuracy: 0.8602\nEpoch 142/200\n28/28 [==============================] - 1s 23ms/step - loss: 0.5711 - accuracy: 0.8396\nEpoch 143/200\n28/28 [==============================] - 1s 23ms/step - loss: 0.5139 - accuracy: 0.8512\nEpoch 144/200\n28/28 [==============================] - 1s 23ms/step - loss: 0.4753 - accuracy: 0.8676\nEpoch 145/200\n28/28 [==============================] - 1s 24ms/step - loss: 0.4654 - accuracy: 0.8682\nEpoch 146/200\n28/28 [==============================] - 1s 26ms/step - loss: 0.4770 - accuracy: 0.8616\nEpoch 147/200\n28/28 [==============================] - 1s 26ms/step - loss: 0.4800 - accuracy: 0.8568\nEpoch 148/200\n28/28 [==============================] - 1s 23ms/step - loss: 0.4413 - accuracy: 0.8677\nEpoch 149/200\n28/28 [==============================] - 1s 22ms/step - loss: 0.5011 - accuracy: 0.8561\nEpoch 150/200\n28/28 [==============================] - 1s 22ms/step - loss: 0.5166 - accuracy: 0.8581\nEpoch 151/200\n28/28 [==============================] - 1s 23ms/step - loss: 0.4774 - accuracy: 0.8653\nEpoch 152/200\n28/28 [==============================] - 1s 23ms/step - loss: 0.4766 - accuracy: 0.8688\nEpoch 153/200\n28/28 [==============================] - 1s 23ms/step - loss: 0.4323 - accuracy: 0.8750\nEpoch 154/200\n28/28 [==============================] - 1s 24ms/step - loss: 0.4178 - accuracy: 0.8805\nEpoch 155/200\n28/28 [==============================] - 1s 23ms/step - loss: 0.4380 - accuracy: 0.8808\nEpoch 156/200\n28/28 [==============================] - 1s 25ms/step - loss: 0.4455 - accuracy: 0.8758\nEpoch 157/200\n28/28 [==============================] - 1s 23ms/step - loss: 0.4602 - accuracy: 0.8705\nEpoch 158/200\n28/28 [==============================] - 1s 23ms/step - loss: 0.4734 - accuracy: 0.8686\nEpoch 159/200\n28/28 [==============================] - 1s 24ms/step - loss: 0.4503 - accuracy: 0.8764\nEpoch 160/200\n28/28 [==============================] - 1s 24ms/step - loss: 0.4490 - accuracy: 0.8650\nEpoch 161/200\n28/28 [==============================] - 1s 23ms/step - loss: 0.4757 - accuracy: 0.8636\nEpoch 162/200\n28/28 [==============================] - 1s 24ms/step - loss: 0.4753 - accuracy: 0.8577\nEpoch 163/200\n28/28 [==============================] - 1s 23ms/step - loss: 0.4359 - accuracy: 0.8685\nEpoch 164/200\n28/28 [==============================] - 1s 23ms/step - loss: 0.4313 - accuracy: 0.8876\nEpoch 165/200\n28/28 [==============================] - 1s 23ms/step - loss: 0.4286 - accuracy: 0.8761\nEpoch 166/200\n28/28 [==============================] - 1s 23ms/step - loss: 0.4589 - accuracy: 0.8684\nEpoch 167/200\n28/28 [==============================] - 1s 23ms/step - loss: 0.4923 - accuracy: 0.8604\nEpoch 168/200\n28/28 [==============================] - 1s 23ms/step - loss: 0.5455 - accuracy: 0.8461\nEpoch 169/200\n28/28 [==============================] - 1s 22ms/step - loss: 0.4552 - accuracy: 0.8741\nEpoch 170/200\n28/28 [==============================] - 1s 23ms/step - loss: 0.4590 - accuracy: 0.8640\nEpoch 171/200\n28/28 [==============================] - 1s 23ms/step - loss: 0.4520 - accuracy: 0.8595\nEpoch 172/200\n28/28 [==============================] - 1s 24ms/step - loss: 0.4985 - accuracy: 0.8573\nEpoch 173/200\n28/28 [==============================] - 1s 23ms/step - loss: 0.4894 - accuracy: 0.8607\nEpoch 174/200\n28/28 [==============================] - 1s 23ms/step - loss: 0.4169 - accuracy: 0.8824\nEpoch 175/200\n28/28 [==============================] - 1s 23ms/step - loss: 0.4748 - accuracy: 0.8636\nEpoch 176/200\n28/28 [==============================] - 1s 22ms/step - loss: 0.4331 - accuracy: 0.8743\nEpoch 177/200\n28/28 [==============================] - 1s 24ms/step - loss: 0.3944 - accuracy: 0.8822\nEpoch 178/200\n28/28 [==============================] - 1s 24ms/step - loss: 0.4290 - accuracy: 0.8797\nEpoch 179/200\n28/28 [==============================] - 1s 24ms/step - loss: 0.4281 - accuracy: 0.8805\nEpoch 180/200\n28/28 [==============================] - 1s 24ms/step - loss: 0.4462 - accuracy: 0.8729\nEpoch 181/200\n28/28 [==============================] - 1s 23ms/step - loss: 0.3879 - accuracy: 0.8871\nEpoch 182/200\n28/28 [==============================] - 1s 25ms/step - loss: 0.4500 - accuracy: 0.8787\nEpoch 183/200\n28/28 [==============================] - 1s 25ms/step - loss: 0.4718 - accuracy: 0.8702\nEpoch 184/200\n28/28 [==============================] - 1s 24ms/step - loss: 0.4299 - accuracy: 0.8795\nEpoch 185/200\n28/28 [==============================] - 1s 24ms/step - loss: 0.3857 - accuracy: 0.8925\nEpoch 186/200\n28/28 [==============================] - 1s 23ms/step - loss: 0.3674 - accuracy: 0.8969\nEpoch 187/200\n28/28 [==============================] - 1s 23ms/step - loss: 0.4223 - accuracy: 0.8792\nEpoch 188/200\n28/28 [==============================] - 1s 23ms/step - loss: 0.4430 - accuracy: 0.8677\nEpoch 189/200\n28/28 [==============================] - 1s 25ms/step - loss: 0.4217 - accuracy: 0.8767\nEpoch 190/200\n28/28 [==============================] - 1s 23ms/step - loss: 0.3904 - accuracy: 0.8891\nEpoch 191/200\n28/28 [==============================] - 1s 23ms/step - loss: 0.4495 - accuracy: 0.8759\nEpoch 192/200\n28/28 [==============================] - 1s 23ms/step - loss: 0.3847 - accuracy: 0.8966\nEpoch 193/200\n28/28 [==============================] - 1s 23ms/step - loss: 0.4136 - accuracy: 0.8872\nEpoch 194/200\n28/28 [==============================] - 1s 23ms/step - loss: 0.3549 - accuracy: 0.8997\nEpoch 195/200\n28/28 [==============================] - 1s 23ms/step - loss: 0.3570 - accuracy: 0.9002\nEpoch 196/200\n28/28 [==============================] - 1s 24ms/step - loss: 0.4011 - accuracy: 0.8908\nEpoch 197/200\n28/28 [==============================] - 1s 28ms/step - loss: 0.3574 - accuracy: 0.9068\nEpoch 198/200\n28/28 [==============================] - 1s 25ms/step - loss: 0.3668 - accuracy: 0.9037\nEpoch 199/200\n28/28 [==============================] - 1s 23ms/step - loss: 0.3968 - accuracy: 0.8974\nEpoch 200/200\n28/28 [==============================] - 1s 24ms/step - loss: 0.3824 - accuracy: 0.8978\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n  warnings.warn('`model.predict_classes()` is deprecated and '\n","output_type":"stream"},{"name":"stdout","text":"12/12 [==============================] - 0s 9ms/step\n0.8430717863105175\n","output_type":"stream"}]}]}